# WaveTransformer

This repository contains a PyTorch implementation of the WaveTransformer architecture, which uses wave-based semantic representations for language modeling.


## Installation

```bash
pip install torch torchvision
pip install datasets tokenizers
pip install flash-attn --no-build-isolation  # For flash attention support
```

## Citation

If you use Wave-Transformer in your research, please cite:

```bibtex
@software{wave_transformer,
  title = {Wave-Transformer: Wave-based Semantic Representations for Transformer Models},
  author = {Maximilian Winter},
  year = {2025},
  url = {https://github.com/Maximilian-Winter/Wave-Transformer}
}
```

## License

This project is licensed under the MIT License.
