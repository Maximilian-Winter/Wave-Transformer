# ðŸŒŠ Wave-Transformer

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-EE4C2C?logo=pytorch)](https://pytorch.org)
[![FlashAttention](https://img.shields.io/badge/FlashAttention-Enabled-blue)](https://github.com/Dao-AILab/flash-attention)

Wave-Transformer is a **PyTorch implementation** of a novel transformer architecture that leverages **wave-based semantic representations**.  
It introduces frequency, amplitude, and phase components into the transformer pipeline for more expressive sequence modeling.

---

## ðŸš€ Installation

```bash
pip install torch torchvision
pip install datasets tokenizers
pip install ninja packaging wheel
pip install flash-attn --no-build-isolation
git clone https://github.com/Maximilian-Winter/Wave-Transformer.git
cd Wave-Transformer
pip install .
````

---

## ðŸ§ª Usage

Later...

---

## ðŸ“„ Citation

If you use Wave-Transformer in your research, please cite:

```bibtex
@software{Wave-Transformer,
  title = {Wave-Transformer: Wave-based Semantic Representations for Transformer Models},
  author = {Maximilian Winter},
  year = {2025},
  url = {https://github.com/Maximilian-Winter/Wave-Transformer}
}
```

---

## ðŸ“œ License

This project is licensed under the [MIT License](LICENSE).
